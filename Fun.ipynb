{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import ViTFeatureExtractor, ViTModel, RobertaTokenizer ,RobertaModel\n",
    "\n",
    "cache_dir = 'Cache/Transformers'\n",
    "\n",
    "vit_model = ViTModel.from_pretrained('google/vit-base-patch16-224-in21k',cache_dir = 'Cache/Transformers')\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224-in21k',cache_dir = 'Cache/Transformers')\n",
    "\n",
    "gpt_tokenizer = RobertaTokenizer.from_pretrained(\"FacebookAI/roberta-base\",cache_dir = 'Cache/Transformers')\n",
    "gpt_model = RobertaModel.from_pretrained(\"FacebookAI/roberta-base\",cache_dir = 'Cache/Transformers')\n",
    "\n",
    "vit_model.eval()\n",
    "gpt_model.eval()\n",
    "\n",
    "def extract_features(image_path):\n",
    "    from PIL import Image\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    inputs = feature_extractor(images=image, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = vit_model(**inputs)\n",
    "    return outputs.last_hidden_state\n",
    "\n",
    "def generate_caption(image_features):\n",
    "    image_features = image_features.mean(dim=1)\n",
    "    \n",
    "    gpt_input = gpt_tokenizer(\"</s>\", return_tensors=\"pt\").input_ids\n",
    "    \n",
    "    gpt_input = gpt_input.expand(image_features.size(0), -1)\n",
    "\n",
    "    print(gpt_input.size())\n",
    "    \n",
    "    generated_ids = gpt_input\n",
    "    for _ in range(50):\n",
    "        \n",
    "        inputs_embeds = torch.cat((image_features, gpt_input), dim=1)\n",
    "        print(inputs_embeds.size())\n",
    "        \n",
    "        outputs = gpt_model(inputs_embeds=inputs_embeds)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        next_token_id = torch.argmax(logits[:, -1, :], dim=-1).unsqueeze(-1)\n",
    "        \n",
    "        gpt_input = torch.cat((gpt_input, next_token_id), dim=1)\n",
    "        \n",
    "        if next_token_id.item() == gpt_tokenizer.eos_token_id:\n",
    "            break\n",
    "    \n",
    "    caption = gpt_tokenizer.decode(gpt_input[0], skip_special_tokens=True)\n",
    "    return caption , image_features\n",
    "\n",
    "image_path = 'Screenshot (3).png'\n",
    "image_features = extract_features(image_path)\n",
    "print(f'Image features:',image_features)\n",
    "\n",
    "caption,image_featuresm = generate_caption(image_features)\n",
    "\n",
    "print(\"Generated Caption:\", caption)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting tensor to numpy array\n",
    "matrix = image_features[0, :, :].numpy()\n",
    "\n",
    "# Plotting as a heatmap\n",
    "plt.imshow(matrix, aspect='auto', cmap='grey')\n",
    "plt.title('Heatmap of sequence vectors (197 x 768)')\n",
    "plt.xlabel('Dimension')\n",
    "plt.ylabel('Sequence index')\n",
    "plt.colorbar(label='Value')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "texts = [\"Hello, my dog is cute\", \"I love machine learning\"]\n",
    "\n",
    "tokenized_inputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "input_ids = tokenized_inputs['input_ids']\n",
    "attention_mask = tokenized_inputs['attention_mask']\n",
    "\n",
    "print(\"Input IDs:\")\n",
    "print(input_ids)\n",
    "print(\"Attention Mask:\")\n",
    "print(attention_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-j-6B\")\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "text_tk = tokenizer(\"hello world!\",max_length=10, padding=\"max_length\", truncation=True,return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text_tk['attention_mask'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, RobertaForCausalLM, AutoConfig\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"FacebookAI/roberta-base\")\n",
    "config = AutoConfig.from_pretrained(\"FacebookAI/roberta-base\")\n",
    "config.is_decoder = True\n",
    "model = RobertaForCausalLM.from_pretrained(\"FacebookAI/roberta-base\", config=config)\n",
    "\n",
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "\n",
    "prediction_logits = outputs.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForQuestionAnswering\n",
    "\n",
    "# Load pre-trained BERT model and tokenizer for QA\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased',cache_dir = 'Cache/Transformers')\n",
    "model = BertForQuestionAnswering.from_pretrained('bert-base-uncased',cache_dir = 'Cache/Transformers')\n",
    "\n",
    "# Define question and context\n",
    "question = \"Who is the president of the United States?\"\n",
    "context = \"The current president of the United States is Joe Biden.\"\n",
    "\n",
    "# Tokenize inputs\n",
    "inputs = tokenizer.encode_plus(question, context, return_tensors='pt', add_special_tokens=True)\n",
    "\n",
    "# Forward pass through the model\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# Get start and end logits from model outputs\n",
    "start_logits = outputs.start_logits\n",
    "end_logits = outputs.end_logits\n",
    "\n",
    "# Convert logits to probabilities\n",
    "start_probs = torch.softmax(start_logits, dim=-1)[0]\n",
    "end_probs = torch.softmax(end_logits, dim=-1)[0]\n",
    "\n",
    "# Get the most probable start and end positions\n",
    "start_index = torch.argmax(start_probs).item()\n",
    "end_index = torch.argmax(end_probs).item()\n",
    "\n",
    "# Get answer span from context\n",
    "tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'].squeeze().tolist())\n",
    "answer = ' '.join(tokens[start_index:end_index+1])\n",
    "\n",
    "print(\"Question:\", question)\n",
    "print(\"Context:\", context)\n",
    "print(\"Answer:\", answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"google-bert/bert-base-uncased\")\n",
    "vocab = tokenizer.vocab\n",
    "print(\"Vocabulary size:\", len(vocab))\n",
    "print(\"Sample tokens:\", list(vocab.keys())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Instantiate the BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "special_tokens_map = tokenizer.special_tokens_map\n",
    "\n",
    "# Print the special tokens map\n",
    "special_tokens_map['eos_token']='[EOS]'\n",
    "print(special_tokens_map['eos_token'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
